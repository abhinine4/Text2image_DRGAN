{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Process captions.ipynb","provenance":[],"mount_file_id":"14H-dXyLgLfsTICFSHBfgLxyqB7yRR9TV","authorship_tag":"ABX9TyOIaRE+ms492WRET7DYQBEo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Processing Captions 🚀**"],"metadata":{"id":"HNZ_h-k1zbc9"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sNE7TNePqetY","executionInfo":{"status":"ok","timestamp":1650740084658,"user_tz":240,"elapsed":126,"user":{"displayName":"SAJ MARU","userId":"12446872909316284903"}},"outputId":"f157802b-4a76-456f-dd00-823cdef6ed68"},"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["# Imports\n","import pandas as pd\n","import pickle\n","import random\n","import gensim\n","import pickle\n","import os\n","import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize\n","import re\n","import numpy as np"]},{"cell_type":"markdown","source":["## **Creating final CSV with image names and corresponding Captions 📈**\n","\n"],"metadata":{"id":"egjxr6YFxxqX"}},{"cell_type":"code","source":["\n","def create_final_csv(caption_path):\n","  with open(caption_path) as f:\n","    content = f.readlines()\n","  content = [x.strip() for x in content]\n","  content = [x.split(\".jpg,\") for x in content]\n","  df = pd.DataFrame(content[1:])\n","  df.columns = ['Images_name','captions']\n","  df = df.drop_duplicates(subset=['Images_name'])\n","  df['Images_name']= df['Images_name'].astype(str)+'.jpg'\n","  df['captions']= df['captions'].str.lower()\n","  df = df.reset_index(drop=True)\n","  df.head()\n","  df.to_csv('/CSVs/flickr8K_final.csv',index=False)\n","\n","caption_path = '/Captions/captions.txt'\n","create_final_csv(caption_path)"],"metadata":{"id":"HALWw3KNrJlz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Cleaning captions, removing puncutaions, Stop Words, Sapces etc... 🔡**"],"metadata":{"id":"w3MpqWG0yN8p"}},{"cell_type":"code","source":["def clean_and_tokenize_comments_for_image(comment):\n","    stop_words = ['a', 'and', 'of', 'to']\n","    punctuation = r\"\"\"!\"#$%&'()*+,./:;<=>?@[\\]^_`…’{|}~\"\"\"\n","    captions_without_punctuation = [s.translate(str.maketrans(' ', ' ', punctuation)) for s in comment]\n","    sentences = []\n","\n","    for clean_caption in captions_without_punctuation:\n","        clean_caption = re.sub(r\"-(?:(?<!\\b[0-9]{4}-)|(?![0-9]{2}(?:[0-9]{2})?\\b))\", ' ', clean_caption)  # replace with space\n","\n","        temp_tokens = word_tokenize(str(clean_caption).lower())\n","        tokens = [t for t in temp_tokens if t not in stop_words]\n","        sentences.append(tokens)\n","    return sentences"],"metadata":{"id":"p8awFMZOtC-6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Generating vectors of captions using Word2Vec 🔢**"],"metadata":{"id":"ZYLg9yY3yros"}},{"cell_type":"code","source":["def create_feature_vectors_for_single_comment(word2vec_model, cleaned_comments, image_names):\n","    vectorized_list = []\n","    image_list = []\n","\n","    for comments, image in zip(cleaned_comments, image_names):\n","        result_array = np.empty((0, 300))\n","        for word in comments:\n","            try:\n","                w = [word2vec_model[word]]\n","                result_array = np.append(result_array, w, axis=0)\n","            except KeyError:\n","                print(word)\n","                result_array = np.append(result_array, [word2vec_model[random.choice(word2vec_model.index2entity)]], axis=0)\n","\n","        vectorized_list.append(np.mean(result_array, axis=0).astype('float32'))\n","        image_list.append(image)\n","\n","    return image_list, np.array(vectorized_list)"],"metadata":{"id":"PNX9EDA3tN4a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Generating embeddings and saving to pickle  🗃️**"],"metadata":{"id":"xeMpA3Gwy8CK"}},{"cell_type":"code","source":["def create_sentence_embeddings():\n","    df = pd.read_csv('CSVs/flickr8K_final.csv')\n","    model = gensim.models.KeyedVectors.load_word2vec_format('/word2vec_pretrained_model/GoogleNews-vectors-negative300.bin', binary=True)\n","    cleaned_captions = clean_and_tokenize_comments_for_image(df['captions'].values)\n","    image_names = df['Images_name'].values\n","    print('Done tokenizing....')\n","    i, c = create_feature_vectors_for_single_comment(model, cleaned_captions, image_names)\n","    word_vector_dict = dict(zip(i, c))\n","    pickle.dump(word_vector_dict, open('/Pickles/flickr8k_embeddings' + \".p\", \"wb\"))\n","    print('Done')\n","\n","create_sentence_embeddings()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VdE4nZYPunKl","executionInfo":{"status":"ok","timestamp":1650740548544,"user_tz":240,"elapsed":60546,"user":{"displayName":"SAJ MARU","userId":"12446872909316284903"}},"outputId":"94aec7f6-c20b-4e41-abe8-2ea0e1fe7959"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Done tokenizing....\n","atvs\n","atvs\n","grey\n","grey\n","bloe\n","grey\n","12\n","diveboard\n","grey\n","grey\n","cathing\n","stonesign\n","panelling\n","medatative\n","grey\n","starbuck\n","grey\n","razzling\n","grey\n","angerly\n","vike\n","attrative\n","grey\n","chasseing\n","foggyday\n","grey\n","grey\n","contracption\n","grey\n","kildare\n","groucho\n","campflauge\n","hawaiin\n","grey\n","vuitton\n","cappedhills\n","grey\n","grey\n","grey\n","ripstik\n","grey\n","broen\n","grey\n","froup\n","bouncey\n","furocious\n","buddist\n","28\n","19\n","catc\n","grey\n","grey\n","busstop\n","darked\n","fton\n","grey\n","outstreached\n","grey\n","lilypads\n","grey\n","medow\n","grey\n","grey\n","streetpole\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n","  out=out, **kwargs)\n","/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in true_divide\n","  ret, rcount, out=ret, casting='unsafe', subok=False)\n"]},{"output_type":"stream","name":"stdout","text":["demonstarting\n","tobaggons\n","budweiser\n","clibing\n","seaguls\n","colourful\n","25\n","standind\n","grey\n","swaetshirt\n","frolicks\n","tourquoise\n","grey\n","bikina\n","saroog\n","surfboarder\n","perforced\n","colourfully\n","worshipping\n","grey\n","horro\n","riwal\n","footbride\n","surfboarder\n","bicylist\n","parasurfer\n","biek\n","drak\n","underhang\n","surfboarder\n","hudge\n","throughwindow\n","grey\n","ractrack\n","kingsworth\n","rollerskater\n","rollerskater\n","christmastime\n","basett\n","biscut\n","grey\n","telephot\n","moustache\n","hurridly\n","downsteps\n","colourful\n","dacshund\n","93\n","lionist\n","grey\n","waing\n","equpitment\n","30\n","halway\n","casque\n","obligatoire\n","outstreached\n","griding\n","seedoo\n","grey\n","grey\n","dooorway\n","dirtbikers\n","battons\n","indescript\n","grey\n","outstreached\n","528\n","tongee\n","retreiver\n","outstreached\n","grey\n","rodderick\n","fronmt\n","281\n","unner\n","grey\n","skislope\n","grey\n","dupar\n","intertube\n","grey\n","penske\n","grey\n","grey\n","colourful\n","headwraps\n","hdr\n","stiped\n","grey\n","obsured\n","bunchh\n","grey\n","waterskies\n","waterskies\n","aggitates\n","grey\n","grey\n","iove\n","outfir\n","shelton\n","grey\n","boogieboard\n","brighty\n","tophats\n","facepaintings\n","surfboarder\n","10\n","gaurdian\n","midpitch\n","woooden\n","plungles\n","rollskating\n","aligator\n","streght\n","swimmies\n","corgie\n","orangesunset\n","dandylions\n","moustache\n","grey\n","petterned\n","grey\n","colourful\n","histerically\n","grey\n","climbes\n","savanah\n","palid\n","silohuetted\n","1950s\n","grey\n","grey\n","cruisship\n","sillhouetted\n","containig\n","grey\n","Done\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"mAw7R4JDu5gZ"},"execution_count":null,"outputs":[]}]}
